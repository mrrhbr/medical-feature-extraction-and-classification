{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OV6K0iGoA0JN"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "#  CheXpert + ViT + LRFL - Fine-Tuning Notebook\n",
        "# ==========================================\n",
        "# Training ViT model for low-Rank Feature Learning (LRFL)\n",
        "# Morvarid Rahbar\n",
        "# 4033624008\n",
        "# =========================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wWmracy0bbA9"
      },
      "outputs": [],
      "source": [
        "# Built-in Libraries\n",
        "import os\n",
        "import copy\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Image & Data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "# Models\n",
        "import timm\n",
        "from torchvision import transforms\n",
        "\n",
        "# Optimizer & Scheduler\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    f1_score,\n",
        "    hamming_loss,\n",
        "    accuracy_score\n",
        ")\n",
        "\n",
        "# Utilities\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Experiment Tracking\n",
        "import wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c_WtItEF6B7e"
      },
      "outputs": [],
      "source": [
        "# wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oPQr6dsK1bvI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a903884-9fb7-45d9-bbf3-9964adca8289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\" Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qDdq3YoesYNw"
      },
      "outputs": [],
      "source": [
        "# LRFL Module\n",
        "class LRFLModel(nn.Module):\n",
        "    def __init__(self, backbone_name='vit_base_patch16_224', rank=64, num_classes=5, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.rank = rank\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.backbone = timm.create_model(backbone_name, pretrained=True, num_classes=0)\n",
        "        self.embed_dim = self.backbone.num_features\n",
        "\n",
        "        self.low_rank_proj = nn.Sequential(\n",
        "            nn.LayerNorm(self.embed_dim),\n",
        "            nn.Linear(self.embed_dim, rank, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.classifier = nn.Linear(rank, num_classes)\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        feats = self.backbone.forward_features(x)\n",
        "        if feats.dim() == 3:  # For ViT-style models\n",
        "            feats = feats[:, 0, :]\n",
        "        return feats\n",
        "\n",
        "    def forward(self, x, return_feats=False):\n",
        "        feats = self.forward_features(x)\n",
        "        proj = self.low_rank_proj(feats)\n",
        "        logits = self.classifier(proj)\n",
        "        return (logits, feats) if return_feats else logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LCBaZU8QnTRM"
      },
      "outputs": [],
      "source": [
        "# BaseLine Model\n",
        "# class BaseModel(nn.Module):\n",
        "#     def __init__(self, backbone_name='vit_base_patch16_224', num_classes=5):\n",
        "#         super().__init__()\n",
        "#         self.backbone = timm.create_model(backbone_name, pretrained=True)\n",
        "\n",
        "#         in_features = self.backbone.head.in_features\n",
        "#         self.backbone.reset_classifier(0)\n",
        "\n",
        "#         self.classifier = nn.Linear(in_features, num_classes)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         feats = self.backbone.forward_features(x)\n",
        "\n",
        "#         logits = self.classifier(feats)\n",
        "#         return logits\n",
        "\n",
        "#     def get_image_embedding(self, x):\n",
        "#         feats = self.backbone.forward_features(x)\n",
        "#         return feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "y2Qm1_wUHz3v"
      },
      "outputs": [],
      "source": [
        "class CheXpertDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.label_cols = [\"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Pleural Effusion\"]\n",
        "\n",
        "\n",
        "        self.data[self.label_cols] = self.data[self.label_cols].fillna(0).replace(-1, 1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        image_path = os.path.join(self.root_dir, row[\"Path\"])\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        labels = row[self.label_cols].values.astype(np.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8TVor3UcKIrX"
      },
      "outputs": [],
      "source": [
        "#  Transforms\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V2Z68yZrrGHb"
      },
      "outputs": [],
      "source": [
        "# LRFL Regularization\n",
        "def compute_uv(features, rank):\n",
        "    with torch.no_grad():\n",
        "        U, _, Vh = torch.linalg.svd(features, full_matrices=False)\n",
        "        return U[:, :rank], Vh[:rank, :]\n",
        "\n",
        "def lrfl_loss_fn(logits, labels, features, U, V, eta=1e-3):\n",
        "    bce = nn.BCEWithLogitsLoss()(logits, labels)\n",
        "    reg = torch.sum((U.T @ features) @ V.T)\n",
        "    return bce + eta * reg / features.size(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xxQUQv1N_5WR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd73c26d-9076-4299-89ea-e8c1d762b63e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Exists: True\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/chexpert_data_v2/train.csv')\n",
        "test_path = df['Path'][0]  # CheXpert-v1.0-small/train/patient00001/study1/view1_frontal.jpg\n",
        "test_path = test_path.replace('CheXpert-v1.0-small/', '')\n",
        "full_path = os.path.join('/content/drive/MyDrive/chexpert_data_v2', test_path)\n",
        "print(\" Exists:\", os.path.exists(full_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VQ28_a3DgnRE"
      },
      "outputs": [],
      "source": [
        "csv_path = \"/content/drive/MyDrive/chexpert_data_v2/train.csv\"\n",
        "img_root = \"/content/drive/MyDrive/chexpert_data_v2\"\n",
        "target_root = \"/content/chexpert_data_v2_selected\"\n",
        "target_root = Path(target_root)\n",
        "target_root.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(csv_path)\n",
        "subset_df = df.sample(frac=0.3 , random_state= 42).reset_index(drop=True)\n",
        "subset_df.to_csv(\"chexpert_30percent.csv\",index = False)"
      ],
      "metadata": {
        "id": "i2kCAJcyABYq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIoVSoefbP0x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f6d16b-98a8-4523-ebee-bfce4609dec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ðŸ“¥ Copying files:  13%|â–ˆâ–Ž        | 8465/67024 [00:23<03:44, 260.41it/s]"
          ]
        }
      ],
      "source": [
        "def copy_file(rel_path_str):\n",
        "    rel_path = Path(rel_path_str.replace(\"CheXpert-v1.0-small/\", \"\"))\n",
        "    src = Path(img_root) / rel_path\n",
        "    dst = target_root / rel_path\n",
        "    try:\n",
        "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
        "        shutil.copy2(src, dst)\n",
        "    except:\n",
        "        return rel_path\n",
        "\n",
        "image_paths = subset_df[\"Path\"].tolist()\n",
        "with ThreadPoolExecutor(max_workers=32) as executor:\n",
        "    list(tqdm(executor.map(copy_file, image_paths), total=len(image_paths), desc=\"ðŸ“¥ Copying files\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlVbI6rq8EY_"
      },
      "outputs": [],
      "source": [
        "!ls /content/drive/MyDrive/chexpert_data_v2/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJZq1u-qfByl"
      },
      "outputs": [],
      "source": [
        "# wandb.init(\n",
        "#     project=\"chexpert-lrf-vit\",\n",
        "#     name=\"run-vit-lrf-v1\",\n",
        "#     config={\n",
        "#         \"lr\": 1e-4,\n",
        "#         \"batch_size\": 128,\n",
        "#         \"epochs\": 10,\n",
        "#         \"model\": \"ViT + LRF\",\n",
        "#         \"rank\": 64\n",
        "#     }\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOVp54Et71b6"
      },
      "outputs": [],
      "source": [
        "#   One Epoch Training\n",
        "def train_one_epoch(model, dataloader, optimizer, device, rank, eta):\n",
        "    model.train()\n",
        "    all_preds, all_labels = [], []\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, feats = model(images, return_feats=True)\n",
        "\n",
        "        U, V = compute_uv(feats, rank)\n",
        "        loss = lrfl_loss_fn(logits, labels, feats, U, V, eta)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        all_preds.append(torch.sigmoid(logits).detach().cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "    preds = torch.cat(all_preds).numpy()\n",
        "    trues = torch.cat(all_labels).numpy()\n",
        "    auc = roc_auc_score(trues, preds, average=\"macro\")\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "\n",
        "    return auc, avg_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf49KPIUb8Fg"
      },
      "outputs": [],
      "source": [
        "#   Validation\n",
        "def evaluate(model, dataloader, device, return_loss=False, rank=32, eta=1e-3):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            logits, feats = model(images, return_feats=True)\n",
        "            U, V = compute_uv(feats, rank)\n",
        "            loss = lrfl_loss_fn(logits, labels, feats, U, V, eta)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            all_preds.append(torch.sigmoid(logits).cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    preds = torch.cat(all_preds).numpy()  # [N, C]\n",
        "    trues = torch.cat(all_labels).numpy()  # [N, C]\n",
        "    bin_preds = (preds > 0.5).astype(int)  # Thresholding\n",
        "\n",
        "    # ===== AUC per class =====\n",
        "    aucs = []\n",
        "    for i in range(trues.shape[1]):\n",
        "        try:\n",
        "            auc = roc_auc_score(trues[:, i], preds[:, i])\n",
        "            aucs.append(auc)\n",
        "        except ValueError:\n",
        "            aucs.append(np.nan)  # skip classes with only one label\n",
        "\n",
        "    mean_auc = np.nanmean(aucs)\n",
        "\n",
        "    # ===== Other metrics =====\n",
        "    f1_macro = f1_score(trues, bin_preds, average='macro', zero_division=0)\n",
        "    f1_micro = f1_score(trues, bin_preds, average='micro', zero_division=0)\n",
        "    hamming = hamming_loss(trues, bin_preds)\n",
        "    acc = accuracy_score(trues, bin_preds)  # not very meaningful in multilabel\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "\n",
        "    print(f\"\\n   Evaluation Metrics:\")\n",
        "    print(f\" -   Mean AUC:      {mean_auc:.4f}\")\n",
        "    print(f\" -   F1 Macro:      {f1_macro:.4f}\")\n",
        "    print(f\" -   F1 Micro:      {f1_micro:.4f}\")\n",
        "    print(f\" -   Hamming Loss:  {hamming:.4f}\")\n",
        "    print(f\" -   Accuracy:      {acc:.4f}\")\n",
        "\n",
        "    if return_loss:\n",
        "        return mean_auc, avg_loss, f1_macro, hamming\n",
        "    return mean_auc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxGcQWZX9uIQ"
      },
      "outputs": [],
      "source": [
        "# # Ù†Ù…Ø§ÛŒØ´ 5 Ù†Ù…ÙˆÙ†Ù‡â€ŒÛŒ ØªØµØ§Ø¯ÙÛŒ Ø§Ø² train_dataset\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# for i in range(5):\n",
        "#     img, label, path = train_dataset[i]\n",
        "#     plt.imshow(img.permute(1, 2, 0))  # Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ [C,H,W] â†’ [H,W,C]\n",
        "#     plt.title(f\"Path: {path}\\nLabels: {label}\")\n",
        "#     plt.axis('off')\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BeDuRCr4XgC"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, optimizer, device, num_epochs=30,\n",
        "          rank=32, eta=1e-3, patience=5, checkpoint_path=\"best_model.pth\", monitor=\"val_loss\"):\n",
        "\n",
        "    # Ù…Ù‚Ø¯Ø§Ø± Ø§ÙˆÙ„ÛŒÙ‡ best_metric Ø¨Ø§ÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¹ÛŒØ§Ø± Ù…ÙˆÙ†ÛŒØªÙˆØ± ØªÙ†Ø¸ÛŒÙ… Ø¨Ø´Ù‡\n",
        "    if monitor in [\"val_loss\", \"hamming\"]:\n",
        "        best_metric = float('inf')\n",
        "    else:\n",
        "        best_metric = -float('inf')  # Ø¨Ø±Ø§ÛŒ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø²Ø±Ú¯ØªØ± Ø¨Ù‡ØªØ±Ù‡ Ù…Ø«Ù„ AUC Ùˆ F1\n",
        "\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n Epoch {epoch+1}/{num_epochs}\")\n",
        "        train_auc, train_loss = train_one_epoch(model, train_loader, optimizer, device, rank, eta)\n",
        "        val_auc, val_loss, val_f1, val_hamming = evaluate(model, val_loader, device, return_loss=True, rank=rank, eta=eta)\n",
        "\n",
        "        print(f\"Train AUC: {train_auc:.4f} | Val AUC: {val_auc:.4f} | Val Loss: {val_loss:.4f} | F1 Macro: {val_f1:.4f} | Hamming: {val_hamming:.4f}\")\n",
        "\n",
        "        if monitor == \"val_auc\":\n",
        "            current_metric = val_auc\n",
        "            improvement = current_metric > best_metric\n",
        "        elif monitor == \"val_f1\":\n",
        "            current_metric = val_f1\n",
        "            improvement = current_metric > best_metric\n",
        "        elif monitor == \"hamming\":\n",
        "            current_metric = val_hamming\n",
        "            improvement = current_metric < best_metric\n",
        "        else:  # val_loss\n",
        "            current_metric = val_loss\n",
        "            improvement = current_metric < best_metric\n",
        "\n",
        "        if improvement:\n",
        "            best_metric = current_metric\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "            print(\" Best model saved.\")\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f\" No improvement for {epochs_no_improve} epoch(s).\")\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(\" Early stopping triggered!\")\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlgBcM1WYZBD"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_dataset = CheXpertDataset(\"chexpert_30percent.csv\", \"/content/chexpert_data_v2_selected\", transform)\n",
        "val_dataset   = CheXpertDataset(\"/content/drive/MyDrive/chexpert_data_v2/valid.csv\", \"/content/drive/MyDrive/chexpert_data_v2\", transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "model = LRFLModel(backbone_name=\"vit_base_patch16_224\", rank=64, num_classes=5).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "    print(\"Batch labels shape:\", labels.shape)\n",
        "    print(\"First batch of labels:\", labels[:5])\n",
        "    break\n"
      ],
      "metadata": {
        "id": "AGfzkxrV7qrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhZblvqurvv_"
      },
      "outputs": [],
      "source": [
        "train(model, train_loader, val_loader, optimizer, device,\n",
        "      num_epochs=20, rank=32, eta=1e-3, patience=5, checkpoint_path=\"best_lrfl_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TU9rzuaW7nf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xRvGevMgm_Y"
      },
      "outputs": [],
      "source": [
        "#  Extract image embeddings and save\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/best_model_LRF30%v2.pth\"))\n",
        "model.eval()\n",
        "\n",
        "image_embeddings = {}\n",
        "with torch.no_grad():\n",
        "    for images, _, paths in tqdm(train_loader):\n",
        "        images = images.to(device)\n",
        "        embs = model.get_image_embedding(images)  # (B, R)\n",
        "        for path, emb in zip(paths, embs):\n",
        "            image_embeddings[path] = emb.cpu()\n",
        "\n",
        "torch.save(image_embeddings, \"/content/drive/MyDrive/image_embeddings_LRF30%.pt\")\n",
        "print(\" Image embeddings saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3jK15v_Xssl"
      },
      "outputs": [],
      "source": [
        "# Flush GPU Memory\n",
        "def clear_cuda_cache():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.synchronize()\n",
        "clear_cuda_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NcqSTxD3ht-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# print(torch.cuda.memory_summary(device=None, abbreviated=False))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}