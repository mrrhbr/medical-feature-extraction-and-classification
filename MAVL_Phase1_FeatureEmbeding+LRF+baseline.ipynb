{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "OV6K0iGoA0JN"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "#  CheXpert + ViT + LRFL - Fine-Tuning Notebook\n",
        "# ==========================================\n",
        "# Training ViT model for low-Rank Feature Learning (LRFL)\n",
        "# Morvarid Rahbar\n",
        "# 4033624008\n",
        "# =========================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "wWmracy0bbA9"
      },
      "outputs": [],
      "source": [
        "# Built-in Libraries\n",
        "import os\n",
        "import copy\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Image & Data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "# Models\n",
        "import timm\n",
        "from torchvision import transforms\n",
        "\n",
        "# Optimizer & Scheduler\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    f1_score,\n",
        "    hamming_loss,\n",
        "    accuracy_score\n",
        ")\n",
        "\n",
        "# Utilities\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Experiment Tracking\n",
        "import wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "c_WtItEF6B7e"
      },
      "outputs": [],
      "source": [
        "# wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "oPQr6dsK1bvI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e78863f0-1026-45da-9d4d-5ad072c802d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\" Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "qDdq3YoesYNw"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LRFLModel(nn.Module):\n",
        "    def __init__(self, backbone_name='vit_base_patch16_224', rank=64, num_classes=5, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.rank = rank\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.backbone = timm.create_model(backbone_name, pretrained=True, num_classes=0)\n",
        "        self.embed_dim = self.backbone.num_features\n",
        "\n",
        "        self.low_rank_proj = nn.Sequential(\n",
        "            nn.LayerNorm(self.embed_dim),\n",
        "            nn.Linear(self.embed_dim, rank, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.classifier = nn.Linear(rank, num_classes)\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        feats = self.backbone.forward_features(x)\n",
        "        if feats.dim() == 3:  # For ViT-style models\n",
        "            feats = feats[:, 0, :]\n",
        "        return feats\n",
        "\n",
        "    def forward(self, x, return_feats=False):\n",
        "        feats = self.forward_features(x)\n",
        "        proj = self.low_rank_proj(feats)\n",
        "        logits = self.classifier(proj)\n",
        "        return (logits, feats) if return_feats else logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "LCBaZU8QnTRM"
      },
      "outputs": [],
      "source": [
        "# class BaseModel(nn.Module):\n",
        "#     def __init__(self, backbone_name='vit_base_patch16_224', num_classes=5):\n",
        "#         super().__init__()\n",
        "#         self.backbone = timm.create_model(backbone_name, pretrained=True)\n",
        "\n",
        "#         in_features = self.backbone.head.in_features\n",
        "#         self.backbone.reset_classifier(0)\n",
        "\n",
        "#         self.classifier = nn.Linear(in_features, num_classes)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         feats = self.backbone.forward_features(x)\n",
        "\n",
        "#         logits = self.classifier(feats)\n",
        "#         return logits\n",
        "\n",
        "#     def get_image_embedding(self, x):\n",
        "#         feats = self.backbone.forward_features(x)\n",
        "#         return feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "y2Qm1_wUHz3v"
      },
      "outputs": [],
      "source": [
        "# ======================  Dataset ======================\n",
        "\n",
        "class CheXpertDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.label_cols = [\n",
        "            'Atelectasis',\n",
        "            'Cardiomegaly',\n",
        "            'Consolidation',\n",
        "            'Edema',\n",
        "            'Pleural Effusion'\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        # Ù…Ø³ÛŒØ± ØªØµÙˆÛŒØ±\n",
        "        relative_path = row['Path'].replace(\"CheXpert-v1.0-small/\", \"\")\n",
        "        img_path = os.path.join(self.img_dir, relative_path)\n",
        "\n",
        "        # Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† ØªØµÙˆÛŒØ±\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ù„ÛŒØ¨Ù„â€ŒÙ‡Ø§\n",
        "        labels = row[self.label_cols]\n",
        "        labels = pd.to_numeric(labels, errors='coerce').fillna(0).astype(np.float32)\n",
        "        labels = torch.tensor(labels.values)  # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ tensor Ø¨Ù‡ Ø´Ú©Ù„ [5]\n",
        "\n",
        "        return image, labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "8TVor3UcKIrX"
      },
      "outputs": [],
      "source": [
        "# ======================  Transforms ======================\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "V2Z68yZrrGHb"
      },
      "outputs": [],
      "source": [
        "# ======================  LRFL Regularization ======================\n",
        "def compute_uv(features, rank):\n",
        "    with torch.no_grad():\n",
        "        U, _, Vh = torch.linalg.svd(features, full_matrices=False)\n",
        "        return U[:, :rank], Vh[:rank, :]\n",
        "\n",
        "def lrfl_loss_fn(logits, labels, features, U, V, eta=1e-3):\n",
        "    bce = nn.BCEWithLogitsLoss()(logits, labels)\n",
        "    reg = torch.sum((U.T @ features) @ V.T)\n",
        "    return bce + eta * reg / features.size(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "xxQUQv1N_5WR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7900916e-608d-4bbf-85ee-2facecbeb453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Exists: True\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/chexpert_data_v2/train.csv')\n",
        "test_path = df['Path'][0]  # CheXpert-v1.0-small/train/patient00001/study1/view1_frontal.jpg\n",
        "test_path = test_path.replace('CheXpert-v1.0-small/', '')\n",
        "full_path = os.path.join('/content/drive/MyDrive/chexpert_data_v2', test_path)\n",
        "print(\" Exists:\", os.path.exists(full_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S8MEUHmzGjot"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "VQ28_a3DgnRE"
      },
      "outputs": [],
      "source": [
        "csv_path = \"/content/drive/MyDrive/chexpert_data_v2/train.csv\"\n",
        "img_root = \"/content/drive/MyDrive/chexpert_data_v2\"\n",
        "target_root = \"/content/chexpert_data_v2_selected\"\n",
        "target_root = Path(target_root)\n",
        "target_root.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "tM_kMTT4gpR8"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(csv_path)\n",
        "subset_df = df.sample(frac=0.3, random_state=42).reset_index(drop=True)\n",
        "subset_df.to_csv(\"chexpert_30percent.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "hIoVSoefbP0x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d635a6f4-099d-44df-c224-60298272a550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ðŸ“¥ Copying files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67024/67024 [03:40<00:00, 304.64it/s]\n"
          ]
        }
      ],
      "source": [
        "def copy_file(rel_path_str):\n",
        "    rel_path = Path(rel_path_str.replace(\"CheXpert-v1.0-small/\", \"\"))\n",
        "    src = Path(img_root) / rel_path\n",
        "    dst = target_root / rel_path\n",
        "    try:\n",
        "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
        "        shutil.copy2(src, dst)\n",
        "    except:\n",
        "        return rel_path\n",
        "\n",
        "image_paths = subset_df[\"Path\"].tolist()\n",
        "with ThreadPoolExecutor(max_workers=32) as executor:\n",
        "    list(tqdm(executor.map(copy_file, image_paths), total=len(image_paths), desc=\"ðŸ“¥ Copying files\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "tlVbI6rq8EY_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d96d56-1b2d-4864-a520-b4b81a7a1f3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train  train.csv  valid  valid.csv\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/chexpert_data_v2/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "uJZq1u-qfByl"
      },
      "outputs": [],
      "source": [
        "# wandb.init(\n",
        "#     project=\"chexpert-lrf-vit\",\n",
        "#     name=\"run-vit-lrf-v1\",\n",
        "#     config={\n",
        "#         \"lr\": 1e-4,\n",
        "#         \"batch_size\": 128,\n",
        "#         \"epochs\": 10,\n",
        "#         \"model\": \"ViT + LRF\",\n",
        "#         \"rank\": 64\n",
        "#     }\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "aOVp54Et71b6"
      },
      "outputs": [],
      "source": [
        "# ======================  One Epoch Training ======================\n",
        "def train_one_epoch(model, dataloader, optimizer, device, rank, eta):\n",
        "    model.train()\n",
        "    all_preds, all_labels = [], []\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, feats = model(images, return_feats=True)\n",
        "\n",
        "        U, V = compute_uv(feats, rank)\n",
        "        loss = lrfl_loss_fn(logits, labels, feats, U, V, eta)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        all_preds.append(torch.sigmoid(logits).detach().cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "    preds = torch.cat(all_preds).numpy()\n",
        "    trues = torch.cat(all_labels).numpy()\n",
        "    auc = roc_auc_score(trues, preds, average=\"macro\")\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "\n",
        "    return auc, avg_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "cf49KPIUb8Fg"
      },
      "outputs": [],
      "source": [
        "# ======================  Validation ======================\n",
        "def evaluate(model, dataloader, device, return_loss=False, rank=32, eta=1e-3):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            logits, feats = model(images, return_feats=True)\n",
        "            U, V = compute_uv(feats, rank)\n",
        "            loss = lrfl_loss_fn(logits, labels, feats, U, V, eta)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            all_preds.append(torch.sigmoid(logits).cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    preds = torch.cat(all_preds).numpy()  # [N, C]\n",
        "    trues = torch.cat(all_labels).numpy()  # [N, C]\n",
        "    bin_preds = (preds > 0.5).astype(int)  # Thresholding\n",
        "\n",
        "    # ===== AUC per class =====\n",
        "    aucs = []\n",
        "    for i in range(trues.shape[1]):\n",
        "        try:\n",
        "            auc = roc_auc_score(trues[:, i], preds[:, i])\n",
        "            aucs.append(auc)\n",
        "        except ValueError:\n",
        "            aucs.append(np.nan)  # skip classes with only one label\n",
        "\n",
        "    mean_auc = np.nanmean(aucs)\n",
        "\n",
        "    # ===== Other metrics =====\n",
        "    f1_macro = f1_score(trues, bin_preds, average='macro', zero_division=0)\n",
        "    f1_micro = f1_score(trues, bin_preds, average='micro', zero_division=0)\n",
        "    hamming = hamming_loss(trues, bin_preds)\n",
        "    acc = accuracy_score(trues, bin_preds)  # not very meaningful in multilabel\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "\n",
        "    print(f\"\\n   Evaluation Metrics:\")\n",
        "    print(f\" -   Mean AUC:      {mean_auc:.4f}\")\n",
        "    print(f\" -   F1 Macro:      {f1_macro:.4f}\")\n",
        "    print(f\" -   F1 Micro:      {f1_micro:.4f}\")\n",
        "    print(f\" -   Hamming Loss:  {hamming:.4f}\")\n",
        "    print(f\" -   Accuracy:      {acc:.4f}\")\n",
        "\n",
        "    if return_loss:\n",
        "        return mean_auc, avg_loss, f1_macro, hamming\n",
        "    return mean_auc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "CxGcQWZX9uIQ"
      },
      "outputs": [],
      "source": [
        "# # Ù†Ù…Ø§ÛŒØ´ 5 Ù†Ù…ÙˆÙ†Ù‡â€ŒÛŒ ØªØµØ§Ø¯ÙÛŒ Ø§Ø² train_dataset\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# for i in range(5):\n",
        "#     img, label, path = train_dataset[i]\n",
        "#     plt.imshow(img.permute(1, 2, 0))  # Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ [C,H,W] â†’ [H,W,C]\n",
        "#     plt.title(f\"Path: {path}\\nLabels: {label}\")\n",
        "#     plt.axis('off')\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_BeDuRCr4XgC"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, optimizer, device, num_epochs=30,\n",
        "          rank=32, eta=1e-3, patience=5, checkpoint_path=\"best_model.pth\", monitor=\"val_loss\"):\n",
        "\n",
        "    # Ù…Ù‚Ø¯Ø§Ø± Ø§ÙˆÙ„ÛŒÙ‡ best_metric Ø¨Ø§ÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¹ÛŒØ§Ø± Ù…ÙˆÙ†ÛŒØªÙˆØ± ØªÙ†Ø¸ÛŒÙ… Ø¨Ø´Ù‡\n",
        "    if monitor in [\"val_loss\", \"hamming\"]:\n",
        "        best_metric = float('inf')\n",
        "    else:\n",
        "        best_metric = -float('inf')  # Ø¨Ø±Ø§ÛŒ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø²Ø±Ú¯ØªØ± Ø¨Ù‡ØªØ±Ù‡ Ù…Ø«Ù„ AUC Ùˆ F1\n",
        "\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n Epoch {epoch+1}/{num_epochs}\")\n",
        "        train_auc, train_loss = train_one_epoch(model, train_loader, optimizer, device, rank, eta)\n",
        "        val_auc, val_loss, val_f1, val_hamming = evaluate(model, val_loader, device, return_loss=True, rank=rank, eta=eta)\n",
        "\n",
        "        print(f\"Train AUC: {train_auc:.4f} | Val AUC: {val_auc:.4f} | Val Loss: {val_loss:.4f} | F1 Macro: {val_f1:.4f} | Hamming: {val_hamming:.4f}\")\n",
        "\n",
        "        if monitor == \"val_auc\":\n",
        "            current_metric = val_auc\n",
        "            improvement = current_metric > best_metric\n",
        "        elif monitor == \"val_f1\":\n",
        "            current_metric = val_f1\n",
        "            improvement = current_metric > best_metric\n",
        "        elif monitor == \"hamming\":\n",
        "            current_metric = val_hamming\n",
        "            improvement = current_metric < best_metric\n",
        "        else:  # val_loss\n",
        "            current_metric = val_loss\n",
        "            improvement = current_metric < best_metric\n",
        "\n",
        "        if improvement:\n",
        "            best_metric = current_metric\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "            print(\" Best model saved.\")\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f\" No improvement for {epochs_no_improve} epoch(s).\")\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(\" Early stopping triggered!\")\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "dlgBcM1WYZBD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "7dc03a25205d4ac1a1d5df9b36b7661f",
            "faf2cf073d514c0599eb7ff60b952c2d",
            "9dcb397c550848c5b8b54747c283a78c",
            "b80770d5d4d2417fa2fd0b1e0d7fd548",
            "d91eb0a58ba44cbb84b53061c6637b55",
            "b0be9e4ddade4c58abfb1be67ddc4ceb",
            "2192b371b4324c249595397c08266c94",
            "7586b6f4814f490b804fd80819a4e239",
            "b5b06c4fe3914898820533870c0833f5",
            "79e357f8a34145dc9d764a488bc76bb7",
            "969714ace5574f77b60d5af5a52f8a25"
          ]
        },
        "outputId": "372398d4-b698-43df-954a-1706bd789e2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dc03a25205d4ac1a1d5df9b36b7661f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_dataset = CheXpertDataset(\"chexpert_30percent.csv\", \"/content/chexpert_data_v2_selected\", transform)\n",
        "val_dataset   = CheXpertDataset(\"/content/drive/MyDrive/chexpert_data_v2/valid.csv\", \"/content/drive/MyDrive/chexpert_data_v2\", transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "model = LRFLModel(backbone_name=\"vit_base_patch16_224\", rank=64, num_classes=5).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T4CfhR3E4Oh7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fdbf609-e1f7-4430-8f0a-b705333a8e0a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xa3RNg-h4QNM"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhZblvqurvv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f2c180c-c5a9-4a89-b097-d91bc61de7bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2649/4189 [23:45<13:51,  1.85it/s]"
          ]
        }
      ],
      "source": [
        "train(model, train_loader, val_loader, optimizer, device,\n",
        "      num_epochs=20, rank=32, eta=1e-3, patience=5, checkpoint_path=\"best_lrfl_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xRvGevMgm_Y"
      },
      "outputs": [],
      "source": [
        "# ====== Extract image embeddings and save ======\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/best_model_LRF30%v2.pth\"))\n",
        "model.eval()\n",
        "\n",
        "image_embeddings = {}\n",
        "with torch.no_grad():\n",
        "    for images, _, paths in tqdm(train_loader):\n",
        "        images = images.to(device)\n",
        "        embs = model.get_image_embedding(images)  # (B, R)\n",
        "        for path, emb in zip(paths, embs):\n",
        "            image_embeddings[path] = emb.cpu()\n",
        "\n",
        "torch.save(image_embeddings, \"/content/drive/MyDrive/image_embeddings_LRF30%.pt\")\n",
        "print(\" Image embeddings saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLyFAfHM1OZu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3jK15v_Xssl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def clear_cuda_cache():\n",
        "    gc.collect()              # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø²Ø¨Ø§Ù„Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒØªÙˆÙ†\n",
        "    torch.cuda.empty_cache()  # Ø®Ø§Ù„ÛŒ Ú©Ø±Ø¯Ù† Ú©Ø´ CUDA\n",
        "    torch.cuda.synchronize()  # Ù…Ù†ØªØ¸Ø± Ø¨Ù…ÙˆÙ†Ù‡ Ù‡Ù…Ù‡ Ø¹Ù…Ù„ÛŒØ§Øª GPU ØªÙ…ÙˆÙ… Ø¨Ø´Ù‡\n",
        "\n",
        "clear_cuda_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NcqSTxD3ht-"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "\n",
        "# print(torch.cuda.memory_summary(device=None, abbreviated=False))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7dc03a25205d4ac1a1d5df9b36b7661f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_faf2cf073d514c0599eb7ff60b952c2d",
              "IPY_MODEL_9dcb397c550848c5b8b54747c283a78c",
              "IPY_MODEL_b80770d5d4d2417fa2fd0b1e0d7fd548"
            ],
            "layout": "IPY_MODEL_d91eb0a58ba44cbb84b53061c6637b55"
          }
        },
        "faf2cf073d514c0599eb7ff60b952c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0be9e4ddade4c58abfb1be67ddc4ceb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2192b371b4324c249595397c08266c94",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "9dcb397c550848c5b8b54747c283a78c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7586b6f4814f490b804fd80819a4e239",
            "max": 346284714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5b06c4fe3914898820533870c0833f5",
            "value": 346284714
          }
        },
        "b80770d5d4d2417fa2fd0b1e0d7fd548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79e357f8a34145dc9d764a488bc76bb7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_969714ace5574f77b60d5af5a52f8a25",
            "value": "â€‡346M/346Mâ€‡[00:01&lt;00:00,â€‡310MB/s]"
          }
        },
        "d91eb0a58ba44cbb84b53061c6637b55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0be9e4ddade4c58abfb1be67ddc4ceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2192b371b4324c249595397c08266c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7586b6f4814f490b804fd80819a4e239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5b06c4fe3914898820533870c0833f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79e357f8a34145dc9d764a488bc76bb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "969714ace5574f77b60d5af5a52f8a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}