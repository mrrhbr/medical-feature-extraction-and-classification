{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "NpxhiOwXAx-D"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import shutil\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import wandb\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_WtItEF6B7e",
        "outputId": "d6310a70-1da8-458c-b86f-c389e108d50d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPQr6dsK1bvI",
        "outputId": "a76488f2-2751-4bdc-b102-6f41d5ecd282"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path = '/content/drive/MyDrive/chexpert_data_v2/train/patient63407'\n",
        "# print(os.path.exists(path))\n"
      ],
      "metadata": {
        "id": "4n0-2Yzr3mR2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSjLhRhWCy5A",
        "outputId": "38af1500-104b-4106-edf9-db046ceb935d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\" Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # ======= LRF =======\n",
        "# class LRFModel(nn.Module):\n",
        "#     def __init__(self, backbone_name='vit_base_patch16_224', rank=64, num_classes=5):\n",
        "#         super().__init__()\n",
        "#         self.backbone = timm.create_model(backbone_name, pretrained=True)\n",
        "#         in_features = self.backbone.head.in_features\n",
        "#         self.backbone.reset_classifier(0)\n",
        "\n",
        "#         self.low_rank_projection = nn.Sequential(\n",
        "#             nn.Linear(in_features, rank, bias=False),\n",
        "#             nn.ReLU()\n",
        "#         )\n",
        "#         self.classifier = nn.Linear(rank, num_classes)\n",
        "\n",
        "#     def forward_features(self, x):\n",
        "#         return self.backbone.forward_features(x)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         feats = self.forward_features(x)\n",
        "#         proj = self.low_rank_projection(feats)\n",
        "#         logits = self.classifier(proj)\n",
        "#         return logits\n",
        "\n",
        "#     def get_image_embedding(self, x):\n",
        "#         feats = self.forward_features(x)\n",
        "#         proj = self.low_rank_projection(feats)\n",
        "#         return proj"
      ],
      "metadata": {
        "id": "qDdq3YoesYNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, backbone_name='vit_base_patch16_224', num_classes=5):\n",
        "        super().__init__()\n",
        "        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ViT Ù¾Ø§ÛŒÙ‡ Ø§Ø² timm\n",
        "        self.backbone = timm.create_model(backbone_name, pretrained=True)\n",
        "\n",
        "        # Ø­Ø°Ù Ù„Ø§ÛŒÙ‡ classifier Ø§ØµÙ„ÛŒ Ù…Ø¯Ù„ (head)\n",
        "        in_features = self.backbone.head.in_features\n",
        "        self.backbone.reset_classifier(0)\n",
        "\n",
        "        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù„Ø§ÛŒÙ‡ Ø®Ø·ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ø®Ø±ÙˆØ¬ÛŒ num_classes\n",
        "        self.classifier = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø§ backbone\n",
        "        feats = self.backbone.forward_features(x)\n",
        "\n",
        "        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "        logits = self.classifier(feats)\n",
        "        return logits\n",
        "\n",
        "    def get_image_embedding(self, x):\n",
        "        # ÙÙ‚Ø· Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (embedding)\n",
        "        feats = self.backbone.forward_features(x)\n",
        "        return feats"
      ],
      "metadata": {
        "id": "LCBaZU8QnTRM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "y2Qm1_wUHz3v"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class CheXpertDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "\n",
        "        self.labels_df = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.label_cols = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³ÛŒØ± Ù†Ø³Ø¨ÛŒ ØªØµÙˆÛŒØ± Ø§Ø² ÙØ§ÛŒÙ„ CSV\n",
        "        img_rel_path = self.labels_df.iloc[idx]['Path']\n",
        "\n",
        "        # Ø­Ø°Ù Ù¾ÛŒØ´ÙˆÙ†Ø¯ \"CheXpert-v1.0-small/\" Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯\n",
        "        if img_rel_path.startswith(\"CheXpert-v1.0-small/\"):\n",
        "            img_rel_path = img_rel_path[len(\"CheXpert-v1.0-small/\"):]\n",
        "\n",
        "        # Ø³Ø§Ø®Øª Ù…Ø³ÛŒØ± Ú©Ø§Ù…Ù„ ØªØµÙˆÛŒØ±\n",
        "        img_path = os.path.join(self.img_dir, img_rel_path)\n",
        "\n",
        "        # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ±ØŒ Ùˆ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ø¨Ø§ ØªØµÙˆÛŒØ± Ø³ÛŒØ§Ù‡ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "        except Exception as e:\n",
        "            print(f\"[WARNING] Could not load image: {img_path} -- {e}\")\n",
        "            image = Image.new('RGB', (224, 224), (0, 0, 0))  # ØªØµÙˆÛŒØ± Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø³ÛŒØ§Ù‡\n",
        "\n",
        "        # Ø§Ø¹Ù…Ø§Ù„ ØªØ±Ù†Ø³ÙÙˆØ±Ù… Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒØ¨Ù„â€ŒÙ‡Ø§ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø§Ù…Ù† Ø¨Ù‡ float32 Ø¨Ø¯ÙˆÙ† Ù‡Ø´Ø¯Ø§Ø±\n",
        "        labels = self.labels_df.iloc[idx][self.label_cols]\n",
        "        labels = labels.infer_objects(copy=False).fillna(0).values.astype('float32')\n",
        "\n",
        "        return image, labels, img_rel_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "8TVor3UcKIrX"
      },
      "outputs": [],
      "source": [
        "# ====== Transforms ======\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load CSVs\n",
        "full_train_df = pd.read_csv('/content/drive/MyDrive/chexpert_data_v2/train.csv')\n",
        "val_df = pd.read_csv('/content/drive/MyDrive/chexpert_data_v2/valid.csv')\n",
        "\n",
        "# Sample 90% of data\n",
        "subset_df = full_train_df.sample(frac=0.7, random_state=42).reset_index(drop=True)\n",
        "subset_df.to_csv(\"chexpert_30percent.csv\", index=False)\n",
        "\n",
        "# Setup paths\n",
        "source_root = '/content/drive/MyDrive/chexpert_data_v2'\n",
        "target_root = '/content/chexpert_data_v2_selected'\n",
        "image_paths = subset_df['Path'].str.replace('CheXpert-v1.0-small/', '', regex=False).tolist()\n",
        "\n",
        "# Create target folder\n",
        "os.makedirs(target_root, exist_ok=True)\n",
        "\n",
        "# Track missing files\n",
        "missing_files = []\n",
        "\n",
        "# Define safe and fast copier\n",
        "def copy_file_fast(rel_path):\n",
        "    src = os.path.join(source_root, rel_path)\n",
        "    dst = os.path.join(target_root, rel_path)\n",
        "    os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "    try:\n",
        "        if not os.path.exists(dst):  # Skip if already copied\n",
        "            shutil.copyfile(src, dst)\n",
        "    except Exception as e:\n",
        "        missing_files.append(rel_path)\n",
        "\n",
        "# Run multi-threaded copying\n",
        "with ThreadPoolExecutor(max_workers=32) as executor:\n",
        "    list(tqdm(executor.map(copy_file_fast, image_paths), total=len(image_paths)))\n",
        "\n",
        "# Save missing files log\n",
        "if missing_files:\n",
        "    pd.DataFrame({'missing': missing_files}).to_csv(\"missing_files.csv\", index=False)\n",
        "    print(f\"âŒ {len(missing_files)} files failed to copy. Saved in missing_files.csv\")\n",
        "else:\n",
        "    print(\"âœ… All files copied successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "hIoVSoefbP0x",
        "outputId": "9e427ed0-9fd7-49dc-ba6e-03a31af8d4ee"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|â–         | 6308/156390 [02:55<1:09:27, 36.01it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0m_result_or_cancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-33-1778138896.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_file_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m                     \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mcancel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \"\"\"\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-33-1778138896.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Run multi-threaded copying\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_file_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/chexpert_data_v2/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlVbI6rq8EY_",
        "outputId": "e65a39dc-b2f5-4fe7-f295-4cd99076e0fc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train  train.csv  valid  valid.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CheXpertDataset(\n",
        "    \"chexpert_30percent.csv\",\n",
        "    \"/content/chexpert_data_v2_selected\",\n",
        "    transform\n",
        ")\n",
        "\n",
        "val_dataset = CheXpertDataset(\n",
        "    \"/content/drive/MyDrive/chexpert_data_v2/valid.csv\",\n",
        "    \"/content/drive/MyDrive/chexpert_data_v2\",\n",
        "    transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "yfTHp6Qb5Y1o"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = BaseModel().to(device)\n",
        "criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "scaler = GradScaler()\n",
        "\n",
        "best_auc = 0\n",
        "early_stop_counter = 0\n",
        "early_stop_patience = 5\n",
        "best_model_state = None\n"
      ],
      "metadata": {
        "id": "THsjkn1jWeto",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "cf381b42800f4764a3e2ccc20f7697a3",
            "ac4474a7efbe4abd8ab9914c68508faf",
            "f54e512cfaf04723aa6378d68ee3935f",
            "8e83cef623fb43fda8fb32b2f4b03548",
            "89ad0ece78e340c9b4f209901c59c1cb",
            "3490bf5080384a3f9fe6602367e6ca85",
            "4fad1c1fe5c6459b8895004d830975da",
            "3cb2896d23924cec9f712f315ba9ae3f",
            "4d2b1e4c38214fc88a5781c493475a72",
            "c256612ea3654977a31931d1360eeb65",
            "4883d84e8ed9465b84ab1c1cf2f7c572"
          ]
        },
        "outputId": "15202dff-de93-4a9e-c59e-cf6f58378845"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf381b42800f4764a3e2ccc20f7697a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-13-582192473.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc87G3OQOHP5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project=\"chexpert-lrf-vit\",\n",
        "    name=\"run-vit-lrf-v1\",\n",
        "    config={\n",
        "        \"lr\": 1e-4,\n",
        "        \"batch_size\": 128,\n",
        "        \"epochs\": 10,\n",
        "        \"model\": \"ViT + LRF\",\n",
        "        \"rank\": 64\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "uJZq1u-qfByl",
        "outputId": "5650860d-689d-4ade-befe-d0f2d72654c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250725_173341-iql30sv5</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit/runs/iql30sv5' target=\"_blank\">run-vit-lrf-v1</a></strong> to <a href='https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit' target=\"_blank\">https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit/runs/iql30sv5' target=\"_blank\">https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit/runs/iql30sv5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit/runs/iql30sv5?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7c0b3da3fc50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aOVp54Et71b6"
      },
      "outputs": [],
      "source": [
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "scaler = GradScaler(device=\"cuda\")\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion, device, scaler):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_labels = []\n",
        "    all_outputs = []\n",
        "\n",
        "    for images, labels, _ in tqdm(dataloader, desc=\"ğŸ§  Training\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast(device_type='cuda'):\n",
        "            outputs = model(images)\n",
        "            outputs = outputs.mean(dim=1)\n",
        "            probs = torch.sigmoid(outputs)\n",
        "\n",
        "            mask = (labels != -1).float()\n",
        "            loss_raw = criterion(outputs, labels)\n",
        "            loss = (loss_raw * mask).sum() / mask.sum().clamp(min=1.0)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "        all_labels.append(labels.detach().cpu())\n",
        "        all_outputs.append(probs.detach().cpu())\n",
        "\n",
        "    y_true = torch.cat(all_labels).numpy()\n",
        "    y_pred = torch.cat(all_outputs).numpy()\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true, y_pred, average='macro')\n",
        "    except:\n",
        "        auc = None\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    return avg_loss, auc\n",
        "\n",
        "\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_labels = []\n",
        "    all_outputs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels, _ in tqdm(dataloader, desc=\"ğŸ” Validation\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            with autocast(device_type='cuda'):\n",
        "                outputs = model(images)\n",
        "                outputs = outputs.mean(dim=1)\n",
        "                probs = torch.sigmoid(outputs)\n",
        "\n",
        "                mask = (labels != -1).float()\n",
        "                loss_raw = criterion(outputs, labels)\n",
        "                loss = (loss_raw * mask).sum() / mask.sum().clamp(min=1.0)\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            all_labels.append(labels.detach().cpu())\n",
        "            all_outputs.append(probs.detach().cpu())\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "\n",
        "    if all_labels and all_outputs:\n",
        "        try:\n",
        "            y_true = torch.cat(all_labels).numpy()\n",
        "            y_pred = torch.cat(all_outputs).numpy()\n",
        "            auc = roc_auc_score(y_true, y_pred, average='macro')\n",
        "        except:\n",
        "            auc = None\n",
        "    else:\n",
        "        auc = None\n",
        "\n",
        "    return avg_loss, auc\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cf49KPIUb8Fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Ù†Ù…Ø§ÛŒØ´ 5 Ù†Ù…ÙˆÙ†Ù‡â€ŒÛŒ ØªØµØ§Ø¯ÙÛŒ Ø§Ø² train_dataset\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# for i in range(5):\n",
        "#     img, label, path = train_dataset[i]\n",
        "#     plt.imshow(img.permute(1, 2, 0))  # Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ [C,H,W] â†’ [H,W,C]\n",
        "#     plt.title(f\"Path: {path}\\nLabels: {label}\")\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n"
      ],
      "metadata": {
        "id": "CxGcQWZX9uIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=20, patience=3, save_path=\"best_model.pth\"):\n",
        "    scaler = GradScaler()\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f\"\\nğŸ“š Epoch {epoch}/{epochs}\")\n",
        "\n",
        "        train_loss, train_auc = train_one_epoch(model, train_loader, optimizer, criterion, device, scaler)\n",
        "        val_loss, val_auc = validate(model, val_loader, criterion, device)\n",
        "\n",
        "        train_auc_str = f\" | ğŸ“Š Train AUC: {train_auc:.4f}\" if train_auc is not None else \"\"\n",
        "        val_auc_str = f\" | ğŸ“ˆ Val AUC: {val_auc:.4f}\" if val_auc is not None else \"\"\n",
        "\n",
        "        print(f\"âœ… Train Loss: {train_loss:.4f}{train_auc_str} | ğŸ§ª Val Loss: {val_loss:.4f}{val_auc_str}\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(\"ğŸ’¾ Model saved!\")\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f\"âš ï¸ No improvement for {epochs_no_improve} epoch(s).\")\n",
        "\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(\"â¹ï¸ Early stopping triggered!\")\n",
        "                break\n",
        "\n",
        "    print(f\"ğŸ¯ Training finished. Best Val Loss: {best_val_loss:.4f}\")"
      ],
      "metadata": {
        "id": "_BeDuRCr4XgC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "sample_path = 'train/patient44846/study1/view1_frontal.jpg'  # ÛŒÚ©ÛŒ Ø§Ø² Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø§Ø±ÙˆØ±ÛŒ\n",
        "img_path = os.path.join('/content/chexpert_data_v2_selected', sample_path)\n",
        "\n",
        "print(\"âœ… Exists:\", os.path.exists(img_path))\n",
        "if os.path.exists(img_path):\n",
        "    Image.open(img_path).show()\n",
        "else:\n",
        "    print(\"ğŸš« Ù…Ø³ÛŒØ± ØªØµÙˆÛŒØ± Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX9Dx0TKqJR1",
        "outputId": "99840ab5-aa6d-4e6d-d954-392478769968"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Exists: False\n",
            "ğŸš« Ù…Ø³ÛŒØ± ØªØµÙˆÛŒØ± Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.exists('/content/drive/MyDrive/chexpert_data_v2/train/patient44846/study1/view1_frontal.jpg')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec84lFRlsA_5",
        "outputId": "4b5be0a8-a42f-40d9-835a-24c91eab3231"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=20, patience=3, save_path=\"/content/best_model.pth\")\n"
      ],
      "metadata": {
        "id": "dlgBcM1WYZBD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Extract image embeddings and save ======\n",
        "model.load_state_dict(torch.load(\"best_model_baseline2.pth\"))\n",
        "model.eval()\n",
        "\n",
        "image_embeddings = {}\n",
        "with torch.no_grad():\n",
        "    for images, _, paths in tqdm(val_loader):\n",
        "        images = images.to(device)\n",
        "        embs = model.get_image_embedding(images)  # (B, R)\n",
        "        for path, emb in zip(paths, embs):\n",
        "            image_embeddings[path] = emb.cpu()\n",
        "\n",
        "torch.save(image_embeddings, \"/content/drive/MyDrive/image_embeddings.pt\")\n",
        "print(\"âœ… Image embeddings saved!\")\n"
      ],
      "metadata": {
        "id": "2xRvGevMgm_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef190842-a170-4f5e-ca5e-121397979f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Image embeddings saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import gc\n",
        "\n",
        "# gc.collect()          # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø­Ø§ÙØ¸Ù‡ Ø¢Ø²Ø§Ø¯ Ø´Ø¯Ù‡ Ø¯Ø± Ù¾Ø§ÛŒØªÙˆÙ†\n",
        "# torch.cuda.empty_cache()  # Ø¢Ø²Ø§Ø¯Ø³Ø§Ø²ÛŒ Ú©Ø´ Ø­Ø§ÙØ¸Ù‡ GPU\n"
      ],
      "metadata": {
        "id": "g3jK15v_Xssl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cf381b42800f4764a3e2ccc20f7697a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac4474a7efbe4abd8ab9914c68508faf",
              "IPY_MODEL_f54e512cfaf04723aa6378d68ee3935f",
              "IPY_MODEL_8e83cef623fb43fda8fb32b2f4b03548"
            ],
            "layout": "IPY_MODEL_89ad0ece78e340c9b4f209901c59c1cb"
          }
        },
        "ac4474a7efbe4abd8ab9914c68508faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3490bf5080384a3f9fe6602367e6ca85",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4fad1c1fe5c6459b8895004d830975da",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "f54e512cfaf04723aa6378d68ee3935f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cb2896d23924cec9f712f315ba9ae3f",
            "max": 346284714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d2b1e4c38214fc88a5781c493475a72",
            "value": 346284714
          }
        },
        "8e83cef623fb43fda8fb32b2f4b03548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c256612ea3654977a31931d1360eeb65",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4883d84e8ed9465b84ab1c1cf2f7c572",
            "value": "â€‡346M/346Mâ€‡[00:01&lt;00:00,â€‡256MB/s]"
          }
        },
        "89ad0ece78e340c9b4f209901c59c1cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3490bf5080384a3f9fe6602367e6ca85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fad1c1fe5c6459b8895004d830975da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cb2896d23924cec9f712f315ba9ae3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d2b1e4c38214fc88a5781c493475a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c256612ea3654977a31931d1360eeb65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4883d84e8ed9465b84ab1c1cf2f7c572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}