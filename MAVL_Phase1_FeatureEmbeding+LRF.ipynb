{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NpxhiOwXAx-D"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import shutil\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_WtItEF6B7e",
        "outputId": "0477e390-620b-4e0b-b199-4974ef621caa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmrahbar-2001\u001b[0m (\u001b[33mmrahbar-2001-university-of-isfahan\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPQr6dsK1bvI",
        "outputId": "d7dc8a79-3fba-4403-9d1a-cdc5e8a21a64"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSjLhRhWCy5A",
        "outputId": "0132959e-7956-4968-dbc7-fbde5fb84b4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\" Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======= LRF =======\n",
        "class LRFModel(nn.Module):\n",
        "    def __init__(self, backbone_name='vit_base_patch16_224', rank=64, num_classes=5):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(backbone_name, pretrained=True)\n",
        "        in_features = self.backbone.head.in_features\n",
        "        self.backbone.reset_classifier(0)\n",
        "\n",
        "        self.low_rank_projection = nn.Sequential(\n",
        "            nn.Linear(in_features, rank, bias=False),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.classifier = nn.Linear(rank, num_classes)\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        return self.backbone.forward_features(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.forward_features(x)\n",
        "        proj = self.low_rank_projection(feats)\n",
        "        logits = self.classifier(proj)\n",
        "        return logits\n",
        "\n",
        "    def get_image_embedding(self, x):\n",
        "        feats = self.forward_features(x)\n",
        "        proj = self.low_rank_projection(feats)\n",
        "        return proj"
      ],
      "metadata": {
        "id": "qDdq3YoesYNw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "y2Qm1_wUHz3v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CheXpertDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:\n",
        "            csv_file (str): Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ CSV Ø´Ø§Ù…Ù„ Ù…Ø³ÛŒØ±Ù‡Ø§ Ùˆ Ù„ÛŒØ¨Ù„â€ŒÙ‡Ø§\n",
        "            img_dir (str): Ù…Ø³ÛŒØ± Ù¾ÙˆØ´Ù‡ Ø§ØµÙ„ÛŒ ØªØµØ§ÙˆÛŒØ±\n",
        "            transform (callable, optional): ØªØ±Ù†Ø³ÙÙˆØ±Ù…â€ŒÙ‡Ø§ÛŒ PyTorch Ø¨Ø±Ø§ÛŒ Ø§Ø¹Ù…Ø§Ù„ Ø±ÙˆÛŒ ØªØµÙˆÛŒØ±\n",
        "        \"\"\"\n",
        "        self.labels_df = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.label_cols = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³ÛŒØ± Ù†Ø³Ø¨ÛŒ ØªØµÙˆÛŒØ± Ø§Ø² ÙØ§ÛŒÙ„ CSV\n",
        "        img_rel_path = self.labels_df.iloc[idx]['Path']\n",
        "\n",
        "        # Ø­Ø°Ù Ù¾ÛŒØ´ÙˆÙ†Ø¯ \"CheXpert-v1.0-small/\" Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯\n",
        "        if img_rel_path.startswith(\"CheXpert-v1.0-small/\"):\n",
        "            img_rel_path = img_rel_path[len(\"CheXpert-v1.0-small/\"):]\n",
        "\n",
        "        # Ø³Ø§Ø®Øª Ù…Ø³ÛŒØ± Ú©Ø§Ù…Ù„ ØªØµÙˆÛŒØ±\n",
        "        img_path = os.path.join(self.img_dir, img_rel_path)\n",
        "\n",
        "        # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ±ØŒ Ùˆ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ø¨Ø§ ØªØµÙˆÛŒØ± Ø³ÛŒØ§Ù‡ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "        except Exception as e:\n",
        "            print(f\"[WARNING] Could not load image: {img_path} -- {e}\")\n",
        "            image = Image.new('RGB', (224, 224), (0, 0, 0))  # ØªØµÙˆÛŒØ± Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø³ÛŒØ§Ù‡\n",
        "\n",
        "        # Ø§Ø¹Ù…Ø§Ù„ ØªØ±Ù†Ø³ÙÙˆØ±Ù… Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒØ¨Ù„â€ŒÙ‡Ø§ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø§Ù…Ù† Ø¨Ù‡ float32 Ø¨Ø¯ÙˆÙ† Ù‡Ø´Ø¯Ø§Ø±\n",
        "        labels = self.labels_df.iloc[idx][self.label_cols]\n",
        "        labels = labels.infer_objects(copy=False).fillna(0).values.astype('float32')\n",
        "\n",
        "        return image, labels, img_rel_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "8TVor3UcKIrX"
      },
      "outputs": [],
      "source": [
        "# ====== Transforms ======\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Loaders ======\n",
        "\n",
        "\n",
        "\n",
        "full_train_df = pd.read_csv('/content/drive/MyDrive/chexpert_data_v2/train.csv')\n",
        "val_df = pd.read_csv('/content/drive/MyDrive/chexpert_data_v2/valid.csv')\n",
        "\n",
        "subset_df = full_train_df.sample(frac=0.3, random_state=42).reset_index(drop=True)\n",
        "subset_df.to_csv(\"chexpert_30percent.csv\", index=False)\n",
        "\n",
        "source_root = '/content/drive/MyDrive/chexpert_data_v2'\n",
        "target_root = '/content/chexpert_data_v2_selected'\n",
        "image_paths = subset_df['Path'].str.replace('CheXpert-v1.0-small/', '', regex=False).tolist()\n",
        "\n",
        "os.makedirs(target_root, exist_ok=True)\n",
        "def copy_file(rel_path):\n",
        "    src = os.path.join(source_root, rel_path)\n",
        "    dst = os.path.join(target_root, rel_path)\n",
        "    os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "    try:\n",
        "        shutil.copy2(src, dst)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "with ThreadPoolExecutor(max_workers=16) as executor:\n",
        "    list(tqdm(executor.map(copy_file, image_paths), total=len(image_paths)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIoVSoefbP0x",
        "outputId": "ddec0406-5012-44a9-cd1f-a22d4b92de7b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67024/67024 [03:25<00:00, 325.80it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/chexpert_data_v2/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlVbI6rq8EY_",
        "outputId": "ae6a175b-dc8a-45e5-a812-1d766d613466"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train  train.csv  valid  valid.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CheXpertDataset(\n",
        "    \"chexpert_30percent.csv\",\n",
        "    \"/content/chexpert_data_v2_selected\",\n",
        "    transform\n",
        ")\n",
        "\n",
        "val_dataset = CheXpertDataset(\n",
        "    \"/content/drive/MyDrive/chexpert_data_v2/valid.csv\",\n",
        "    \"/content/drive/MyDrive/chexpert_data_v2\",\n",
        "    transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "yfTHp6Qb5Y1o"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Dc87G3OQOHP5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97181526-aab8-4bab-a57a-4bb816a9b3fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-54-4007471735.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# ====== Training setup ======\n",
        "model = LRFModel().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
        "scaler = GradScaler()\n",
        "criterion = nn.BCEWithLogitsLoss(reduction='none')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project=\"chexpert-lrf-vit\",\n",
        "    name=\"run-vit-lrf-v1\",\n",
        "    config={\n",
        "        \"lr\": 1e-4,\n",
        "        \"batch_size\": 128,\n",
        "        \"epochs\": 10,\n",
        "        \"model\": \"ViT + LRF\",\n",
        "        \"rank\": 64\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "uJZq1u-qfByl",
        "outputId": "f27aa42f-b714-4e05-ae90-9f9474566f13"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-vit-lrf-v1</strong> at: <a href='https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit/runs/mwmbdxcz' target=\"_blank\">https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit/runs/mwmbdxcz</a><br> View project at: <a href='https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit' target=\"_blank\">https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250724_200035-mwmbdxcz/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250724_200621-p6vjmec1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit/runs/p6vjmec1' target=\"_blank\">run-vit-lrf-v1</a></strong> to <a href='https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit' target=\"_blank\">https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit/runs/p6vjmec1' target=\"_blank\">https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit/runs/p6vjmec1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit/runs/p6vjmec1?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fbcfcd8ac10>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "aOVp54Et71b6"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels, _ in tqdm(dataloader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(images)\n",
        "            outputs = outputs.mean(dim=1)\n",
        "            mask = (labels != -1).float()\n",
        "            loss_raw = criterion(outputs, labels)\n",
        "\n",
        "            # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÙ‚Ø³ÛŒÙ… Ø¨Ø± ØµÙØ±\n",
        "            if mask.sum() > 0:\n",
        "                loss = (loss_raw * mask).sum() / mask.sum()\n",
        "            else:\n",
        "                loss = loss_raw.mean()\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "    return total_loss / len(dataloader.dataset)\n",
        "\n",
        "\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels, _ in tqdm(dataloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "                outputs = outputs.mean(dim=1)\n",
        "                mask = (labels != -1).float()\n",
        "                loss_raw = criterion(outputs, labels)\n",
        "\n",
        "                if mask.sum() > 0:\n",
        "                    loss = (loss_raw * mask).sum() / mask.sum()\n",
        "                else:\n",
        "                    loss = loss_raw.mean()\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "    return total_loss / len(dataloader.dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cf49KPIUb8Fg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Ù†Ù…Ø§ÛŒØ´ 5 Ù†Ù…ÙˆÙ†Ù‡â€ŒÛŒ ØªØµØ§Ø¯ÙÛŒ Ø§Ø² train_dataset\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# for i in range(5):\n",
        "#     img, label, path = train_dataset[i]\n",
        "#     plt.imshow(img.permute(1, 2, 0))  # Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ [C,H,W] â†’ [H,W,C]\n",
        "#     plt.title(f\"Path: {path}\\nLabels: {label}\")\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n"
      ],
      "metadata": {
        "id": "CxGcQWZX9uIQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val = float('inf')\n",
        "for epoch in range(10):\n",
        "    print(f\"\\nğŸ“š Epoch {epoch+1}/10\")\n",
        "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "    val_loss = validate(model, val_loader, criterion, device)\n",
        "    print(f\"âœ… Train Loss: {train_loss:.4f} | ğŸ§ª Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    if val_loss < best_val:\n",
        "        best_val = val_loss\n",
        "        torch.save(model.state_dict(), \"best_lrf_model.pt\")\n",
        "        print(\"ğŸ’¾ Best model saved!\")\n",
        "\n",
        "    scheduler.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BeDuRCr4XgC",
        "outputId": "9521cbda-f53b-41c2-95ee-a6b7594f6d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1048 [00:00<?, ?it/s]/tmp/ipython-input-39-1551112850.py:8: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1048/1048 [09:06<00:00,  1.92it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 1/4 [01:38<04:56, 98.67s/it]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [03:10<03:08, 94.37s/it]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [04:58<01:41, 101.03s/it]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [06:11<00:00, 92.93s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Train Loss: 0.4231 | ğŸ§ª Val Loss: 0.4721\n",
            "ğŸ’¾ Best model saved!\n",
            "\n",
            "ğŸ“š Epoch 2/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1048 [00:00<?, ?it/s]/tmp/ipython-input-39-1551112850.py:8: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1048/1048 [09:04<00:00,  1.93it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.84it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.86it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Train Loss: 0.3823 | ğŸ§ª Val Loss: 0.4694\n",
            "ğŸ’¾ Best model saved!\n",
            "\n",
            "ğŸ“š Epoch 3/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1048 [00:00<?, ?it/s]/tmp/ipython-input-39-1551112850.py:8: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1048/1048 [09:06<00:00,  1.92it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.75it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.74it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Train Loss: 0.3638 | ğŸ§ª Val Loss: 0.4946\n",
            "\n",
            "ğŸ“š Epoch 4/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1048 [00:00<?, ?it/s]/tmp/ipython-input-39-1551112850.py:8: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1048/1048 [09:06<00:00,  1.92it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.86it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.00it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Train Loss: 0.3251 | ğŸ§ª Val Loss: 0.4532\n",
            "ğŸ’¾ Best model saved!\n",
            "\n",
            "ğŸ“š Epoch 5/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1048 [00:00<?, ?it/s]/tmp/ipython-input-39-1551112850.py:8: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1048/1048 [09:04<00:00,  1.92it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.85it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Train Loss: 0.2837 | ğŸ§ª Val Loss: 0.5079\n",
            "\n",
            "ğŸ“š Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1048 [00:00<?, ?it/s]/tmp/ipython-input-39-1551112850.py:8: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1048/1048 [09:06<00:00,  1.92it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.57it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.69it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Train Loss: 0.2265 | ğŸ§ª Val Loss: 0.5412\n",
            "\n",
            "ğŸ“š Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1048 [00:00<?, ?it/s]/tmp/ipython-input-39-1551112850.py:8: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1048/1048 [09:05<00:00,  1.92it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:02,  1.43it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.46it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.61it/s]/tmp/ipython-input-39-1551112850.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Train Loss: 0.1296 | ğŸ§ª Val Loss: 0.7918\n",
            "\n",
            "ğŸ“š Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1048 [00:00<?, ?it/s]/tmp/ipython-input-39-1551112850.py:8: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 656/1048 [05:41<03:34,  1.83it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Extract image embeddings and save ======\n",
        "model.load_state_dict(torch.load(\"best_lrf_model.pt\"))\n",
        "model.eval()\n",
        "\n",
        "image_embeddings = {}\n",
        "with torch.no_grad():\n",
        "    for images, _, paths in tqdm(val_loader):\n",
        "        images = images.to(device)\n",
        "        embs = model.get_image_embedding(images)  # (B, R)\n",
        "        for path, emb in zip(paths, embs):\n",
        "            image_embeddings[path] = emb.cpu()\n",
        "\n",
        "torch.save(image_embeddings, \"/content/drive/MyDrive/image_embeddings.pt\")\n",
        "print(\"âœ… Image embeddings saved!\")\n"
      ],
      "metadata": {
        "id": "2xRvGevMgm_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import gc\n",
        "\n",
        "# gc.collect()          # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø­Ø§ÙØ¸Ù‡ Ø¢Ø²Ø§Ø¯ Ø´Ø¯Ù‡ Ø¯Ø± Ù¾Ø§ÛŒØªÙˆÙ†\n",
        "# torch.cuda.empty_cache()  # Ø¢Ø²Ø§Ø¯Ø³Ø§Ø²ÛŒ Ú©Ø´ Ø­Ø§ÙØ¸Ù‡ GPU\n"
      ],
      "metadata": {
        "id": "g3jK15v_Xssl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}