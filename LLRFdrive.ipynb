{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NpxhiOwXAx-D"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.cuda.amp import autocast, GradScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSjLhRhWCy5A",
        "outputId": "f2086190-5737-4e4b-b006-58f42b9f80a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MPyIwsSgfno",
        "outputId": "b0be4fca-d5a0-412c-cc18-a8e587b8a9fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "KSYqphU2QfV2"
      },
      "outputs": [],
      "source": [
        "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6lJvRbXjXRw"
      },
      "outputs": [],
      "source": [
        "# %cd /content/drive/MyDrive/\n",
        "# !kaggle datasets download -d ashery/chexpert -p chexpert_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0A8HnZlDGWOz"
      },
      "outputs": [],
      "source": [
        "model = timm.create_model('vit_base_patch16_224', pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "y2Qm1_wUHz3v"
      },
      "outputs": [],
      "source": [
        "class CheXpertDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "\n",
        "        self.labels_df = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # ŸÖÿ≥€åÿ± ŸÜÿ≥ÿ®€å ÿ™ÿµŸà€åÿ± ÿßÿ≤ ÿ≥ÿ™ŸàŸÜ CSV\n",
        "        img_rel_path = self.labels_df.iloc[idx]['Path']\n",
        "\n",
        "        # ÿ≠ÿ∞ŸÅ Ÿæ€åÿ¥ŸàŸÜÿØ \"CheXpert-v1.0-small\" ÿß⁄Øÿ± ÿØÿ± ŸÖÿ≥€åÿ± ÿ®ŸàÿØ\n",
        "        if img_rel_path.startswith(\"CheXpert-v1.0-small\"):\n",
        "            img_rel_path = img_rel_path[len(\"CheXpert-v1.0-small\")+1:]  # +1 ÿ®ÿ±ÿß€å ÿ≠ÿ∞ŸÅ ÿßÿ≥ŸÑÿ¥ ÿ®ÿπÿØ€å\n",
        "\n",
        "        # ŸÖÿ≥€åÿ± ⁄©ÿßŸÖŸÑ ÿ™ÿµŸà€åÿ± ÿ®ÿß join ⁄©ÿ±ÿØŸÜ ŸÖÿ≥€åÿ± ÿ±€åÿ¥Ÿá Ÿà ŸÖÿ≥€åÿ± ŸÜÿ≥ÿ®€å ÿßÿµŸÑÿßÿ≠ ÿ¥ÿØŸá\n",
        "        img_path = os.path.join(self.img_dir, img_rel_path)\n",
        "\n",
        "        # ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ÿ™ÿµŸà€åÿ± ÿ®ÿß ÿ™ÿ®ÿØ€åŸÑ ÿ®Ÿá RGB (3 ⁄©ÿßŸÜÿßŸÑŸá)\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "        except Exception as e:\n",
        "            print(f\"[WARNING] Could not load image: {img_path} -- {e}\")\n",
        "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # ⁄Øÿ±ŸÅÿ™ŸÜ ŸÑ€åÿ®ŸÑ‚ÄåŸáÿß Ÿà infer_objects ÿ®ÿ±ÿß€å ÿ¨ŸÑŸà⁄Ø€åÿ±€å ÿßÿ≤ warning\n",
        "        labels = self.labels_df.iloc[idx][['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']]\n",
        "        labels = labels.infer_objects(copy=False).fillna(0).values.astype('float32')\n",
        "\n",
        "        return image, labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8TVor3UcKIrX"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_csv_file='/content/drive/MyDrive/chexpert_data_v2/train.csv'\n",
        "df = pd.read_csv(base_csv_file)\n"
      ],
      "metadata": {
        "id": "a6CVkZaoMpLJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_valid_file='/content/drive/MyDrive/chexpert_data_v2/valid.csv'\n",
        "dfvalid = pd.read_csv(base_valid_file)\n"
      ],
      "metadata": {
        "id": "v718Ng9sAFQf"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset = df.sample(frac=0.3, random_state=42).reset_index(drop=True)\n",
        "df_valid_subset=dfvalid.sample(frac=0.3, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "r_cyrdOJM-aQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset.to_csv(\"chexpert_30percent.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "2BMUMkV4NY79"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_valid_subset.to_csv(\"chexpert_30percen_valid.csv\", index=False)"
      ],
      "metadata": {
        "id": "WyuyZHB1NbWm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Dc87G3OQOHP5"
      },
      "outputs": [],
      "source": [
        "train_dataset = CheXpertDataset(\n",
        "    csv_file=\"chexpert_30percent.csv\",\n",
        "    img_dir='/content/drive/MyDrive/chexpert_data_v2/',\n",
        "    transform=transform\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "xHYlC0R3N6A-"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "wV_xD_4vOJ2B"
      },
      "outputs": [],
      "source": [
        "val_dataset = CheXpertDataset(\n",
        "    csv_file=\"chexpert_30percen_valid.csv\",\n",
        "    img_dir='/content/drive/MyDrive/chexpert_data_v2/',\n",
        "    transform=transform\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "LBy_-oKPPfvv"
      },
      "outputs": [],
      "source": [
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "MMjucHDMPu2Y"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "wCgnfTC0Qbii"
      },
      "outputs": [],
      "source": [
        "model.head = nn.Linear(model.head.in_features, 5)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "QFnWP63KxwjG"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "del images, labels, outputs, loss\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "v7C4mHwGH4Kh"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O_QGF5xVcPtQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "QZU1P_CGQdlO",
        "outputId": "20911d91-766a-47a5-cfb2-8f4e1c05e141"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'GradScaler' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-4232214370.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_subset_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m  \u001b[0;31m# ŸÅŸÇÿ∑ 30Ÿ™ ÿßÿ≤ val ÿ®ÿ±ÿß€å ÿßÿ±ÿ≤€åÿßÿ®€å\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GradScaler' is not defined"
          ]
        }
      ],
      "source": [
        "scaler = GradScaler()\n",
        "num_epochs = 5\n",
        "val_subset_ratio = 0.3  # ŸÅŸÇÿ∑ 30Ÿ™ ÿßÿ≤ val ÿ®ÿ±ÿß€å ÿßÿ±ÿ≤€åÿßÿ®€å\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nüìö Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    # -------------------------\n",
        "    # üîÅ ŸÖÿ±ÿ≠ŸÑŸá Training\n",
        "    # -------------------------\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_loop = tqdm(train_loader, desc=\"üîß Training\", leave=False)\n",
        "\n",
        "    for images, labels in train_loop:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True).float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():  # mixed precision training\n",
        "            outputs = model(images)\n",
        "            mask = (labels != -1).float()\n",
        "            loss_raw = criterion(outputs, labels)\n",
        "            loss = (loss_raw * mask).sum() / mask.sum()\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        train_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
        "    print(f\"‚úÖ Avg Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # -------------------------\n",
        "    # üîç ŸÖÿ±ÿ≠ŸÑŸá Validation\n",
        "    # -------------------------\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_loop = tqdm(val_loader, desc=\"üß™ Validating\", leave=False)\n",
        "    max_val_batches = int(len(val_loader) * val_subset_ratio)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, labels) in enumerate(val_loop):\n",
        "            if i > max_val_batches:\n",
        "                break\n",
        "\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True).float()\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "                mask = (labels != -1).float()\n",
        "                loss_raw = criterion(outputs, labels)\n",
        "                loss = (loss_raw * mask).sum() / mask.sum()\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            val_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_val_loss = val_loss / (max_val_batches * val_loader.batch_size)\n",
        "    print(f\"üß™ Avg Val Loss: {avg_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oRtVvNYxRnlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e7c8836-e66d-4420-9676-b352973fac17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.path.exists('/content/drive/MyDrive/chexpert_data_v2/train/patient20948/study2/view1_frontal.jpg'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYbXckv07sgD",
        "outputId": "d090ed08-babd-4397-adf6-09558c94da9d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Image is valid.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aOVp54Et71b6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "609gW-qmG3zz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}