{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xsYxqSbr57zy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NpxhiOwXAx-D"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import shutil\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_WtItEF6B7e",
        "outputId": "06962898-e318-4f7a-ac2f-db4a4d7fd880"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmrahbar-2001\u001b[0m (\u001b[33mmrahbar-2001-university-of-isfahan\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPQr6dsK1bvI",
        "outputId": "0b2047c2-116f-4351-e44a-733dbcaf5e62"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSjLhRhWCy5A",
        "outputId": "e356910d-c697-45f4-b42c-5c2c1dfdb326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======= LRF =======\n",
        "class LRFModel(nn.Module):\n",
        "    def __init__(self, backbone_name='vit_base_patch16_224', rank=64, num_classes=5):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(backbone_name, pretrained=True)\n",
        "        in_features = self.backbone.head.in_features\n",
        "        self.backbone.reset_classifier(0)\n",
        "        self.low_rank_head = nn.Sequential(\n",
        "            nn.Linear(in_features, rank, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(rank, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone.forward_features(x)  # [B, 197, D] €åÿß [B, D]\n",
        "        if feats.ndim == 3:\n",
        "            feats = feats[:, 0]  # €åÿß feats.mean(dim=1) ÿ®ÿ≥ÿ™Ÿá ÿ®Ÿá ŸÖŸÇÿßŸÑŸá\n",
        "        return self.low_rank_head(feats)\n"
      ],
      "metadata": {
        "id": "qDdq3YoesYNw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "y2Qm1_wUHz3v"
      },
      "outputs": [],
      "source": [
        "class CheXpertDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "\n",
        "        self.labels_df = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # ŸÖÿ≥€åÿ± ŸÜÿ≥ÿ®€å ÿ™ÿµŸà€åÿ± ÿßÿ≤ ÿ≥ÿ™ŸàŸÜ CSV\n",
        "        img_rel_path = self.labels_df.iloc[idx]['Path']\n",
        "\n",
        "        # ÿ≠ÿ∞ŸÅ Ÿæ€åÿ¥ŸàŸÜÿØ \"CheXpert-v1.0-small\" ÿß⁄Øÿ± ÿØÿ± ŸÖÿ≥€åÿ± ÿ®ŸàÿØ\n",
        "        if img_rel_path.startswith(\"CheXpert-v1.0-small\"):\n",
        "            img_rel_path = img_rel_path[len(\"CheXpert-v1.0-small\")+1:]  # +1 ÿ®ÿ±ÿß€å ÿ≠ÿ∞ŸÅ ÿßÿ≥ŸÑÿ¥ ÿ®ÿπÿØ€å\n",
        "\n",
        "        # ŸÖÿ≥€åÿ± ⁄©ÿßŸÖŸÑ ÿ™ÿµŸà€åÿ± ÿ®ÿß join ⁄©ÿ±ÿØŸÜ ŸÖÿ≥€åÿ± ÿ±€åÿ¥Ÿá Ÿà ŸÖÿ≥€åÿ± ŸÜÿ≥ÿ®€å ÿßÿµŸÑÿßÿ≠ ÿ¥ÿØŸá\n",
        "        img_path = os.path.join(self.img_dir, img_rel_path)\n",
        "\n",
        "        # ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ÿ™ÿµŸà€åÿ± ÿ®ÿß ÿ™ÿ®ÿØ€åŸÑ ÿ®Ÿá RGB (3 ⁄©ÿßŸÜÿßŸÑŸá)\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "        except Exception as e:\n",
        "            print(f\"[WARNING] Could not load image: {img_path} -- {e}\")\n",
        "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # ⁄Øÿ±ŸÅÿ™ŸÜ ŸÑ€åÿ®ŸÑ‚ÄåŸáÿß Ÿà infer_objects ÿ®ÿ±ÿß€å ÿ¨ŸÑŸà⁄Ø€åÿ±€å ÿßÿ≤ warning\n",
        "        labels = self.labels_df.iloc[idx][['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']]\n",
        "        labels = labels.infer_objects(copy=False).fillna(0).values.astype('float32')\n",
        "\n",
        "        return image, labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8TVor3UcKIrX"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0A8HnZlDGWOz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/chexpert_data_v2/train.csv')\n",
        "dfvalid = pd.read_csv('/content/drive/MyDrive/chexpert_data_v2/valid.csv')\n",
        "df_subset = df.sample(frac=0.3, random_state=42).reset_index(drop=True)\n",
        "df_subset.to_csv(\"chexpert_30percent.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "fPVdGlDN15-2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = 'chexpert_30percent.csv'\n",
        "source_root = '/content/drive/MyDrive/chexpert_data_v2'\n",
        "target_root = '/content/chexpert_data_v2_selected'\n",
        "df = pd.read_csv(csv_path)\n",
        "image_paths = df['Path'].str.replace('CheXpert-v1.0-small/', '', regex=False).tolist()\n"
      ],
      "metadata": {
        "id": "8A0lpLIQ2R1s"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def copy_file(rel_path):\n",
        "    src = os.path.join(source_root, rel_path)\n",
        "    dst = os.path.join(target_root, rel_path)\n",
        "    os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "    try:\n",
        "        shutil.copy2(src, dst)\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "os.makedirs(target_root, exist_ok=True)\n",
        "with ThreadPoolExecutor(max_workers=8) as executor:\n",
        "    list(tqdm(executor.map(copy_file, image_paths), total=len(image_paths)))"
      ],
      "metadata": {
        "id": "-GLcqtjnY65r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======= DataLoaders =======\n",
        "train_dataset = CheXpertDataset('chexpert_30percent.csv', target_root, transform)\n",
        "val_dataset = CheXpertDataset('/content/drive/MyDrive/chexpert_data_v2/valid.csv',\n",
        "                              '/content/drive/MyDrive/chexpert_data_v2', transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "1kcNeCFXL-Cb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Dc87G3OQOHP5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "973e7bb1-49aa-4390-b53f-f973045cab49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-15-1887096189.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ],
      "source": [
        "model = LRFModel().to(device)\n",
        "criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
        "scaler = GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project=\"chexpert-lrf-vit\",\n",
        "    name=\"run-vit-lrf-v1\",\n",
        "    config={\n",
        "        \"lr\": 1e-4,\n",
        "        \"batch_size\": 128,\n",
        "        \"epochs\": 10,\n",
        "        \"model\": \"ViT + LRF\",\n",
        "        \"rank\": 64\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "uJZq1u-qfByl",
        "outputId": "6f3735c9-06f8-4da9-b626-f0f282556a4c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250723_133219-eqnt35ha</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit/runs/eqnt35ha' target=\"_blank\">run-vit-lrf-v1</a></strong> to <a href='https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit' target=\"_blank\">https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit/runs/eqnt35ha' target=\"_blank\">https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit/runs/eqnt35ha</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mrahbar-2001-university-of-isfahan/chexpert-lrf-vit/runs/eqnt35ha?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7e015879b110>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "aOVp54Et71b6"
      },
      "outputs": [],
      "source": [
        "def validate(model, dataloader, subset_ratio=0.3):\n",
        "    model.eval()\n",
        "    val_loss, all_labels, all_outputs = 0, [], []\n",
        "    max_batches = int(len(dataloader) * subset_ratio)\n",
        "    auc_scores = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, labels) in enumerate(tqdm(dataloader, desc=\"üß™ Validating\", leave=False)):\n",
        "            if i > max_batches: break\n",
        "            images, labels = images.to(device), labels.to(device).float()\n",
        "            with autocast():\n",
        "                outputs = model(images)  # shape: [B, 197, 5]\n",
        "                outputs = outputs.mean(dim=1)  # üîß ŸáŸÖ€åŸÜ ÿÆÿ∑ ⁄©ŸÑ ŸÖÿ¥⁄©ŸÑ ÿ±Ÿà ÿ≠ŸÑ ŸÖ€å‚Äå⁄©ŸÜŸá\n",
        "                mask = (labels != -1).float()\n",
        "                loss_raw = criterion(outputs, labels)\n",
        "                loss = (loss_raw * mask).sum() / mask.sum()\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "            all_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n",
        "\n",
        "    avg_loss = val_loss / (max_batches * dataloader.batch_size)\n",
        "\n",
        "    try:\n",
        "        all_labels = np.concatenate(all_labels)\n",
        "        all_outputs = np.concatenate(all_outputs)\n",
        "        for i, disease in enumerate(['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']):\n",
        "            try:\n",
        "                auc = roc_auc_score(all_labels[:, i], all_outputs[:, i])\n",
        "                auc_scores[disease] = auc\n",
        "                print(f\"‚úÖ AUC {disease}: {auc:.4f}\")\n",
        "            except:\n",
        "                auc_scores[disease] = float('nan')\n",
        "                print(f\"‚ö†Ô∏è AUC {disease}: Not enough data\")\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è AUC skipped due to shape issues\")\n",
        "\n",
        "    return avg_loss, auc_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, dataloader, subset_ratio=0.3):\n",
        "    model.eval()\n",
        "    val_loss, all_labels, all_outputs = 0, [], []\n",
        "    max_batches = int(len(dataloader) * subset_ratio)\n",
        "    auc_scores = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, labels) in enumerate(tqdm(dataloader, desc=\"üß™ Validating\", leave=False)):\n",
        "            if i > max_batches: break\n",
        "            images, labels = images.to(device), labels.to(device).float()\n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "                mask = (labels != -1).float()\n",
        "                loss_raw = criterion(outputs, labels)\n",
        "                loss = (loss_raw * mask).sum() / mask.sum()\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "            all_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n",
        "\n",
        "    avg_loss = val_loss / (max_batches * dataloader.batch_size)\n",
        "\n",
        "    try:\n",
        "        all_labels = np.concatenate(all_labels)\n",
        "        all_outputs = np.concatenate(all_outputs)\n",
        "        for i, disease in enumerate(['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']):\n",
        "            try:\n",
        "                auc = roc_auc_score(all_labels[:, i], all_outputs[:, i])\n",
        "                auc_scores[disease] = auc\n",
        "                print(f\"‚úÖ AUC {disease}: {auc:.4f}\")\n",
        "            except:\n",
        "                auc_scores[disease] = float('nan')\n",
        "                print(f\"‚ö†Ô∏è AUC {disease}: Not enough data\")\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è AUC skipped due to shape issues\")\n",
        "\n",
        "    return avg_loss, auc_scores\n"
      ],
      "metadata": {
        "id": "cf49KPIUb8Fg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(10):\n",
        "    print(f\"\\nüìö Epoch {epoch+1}/10\")\n",
        "\n",
        "    train_loss = train_one_epoch(model, train_loader)\n",
        "    val_loss, auc_scores = validate(model, val_loader)\n",
        "\n",
        "    # ÿ∞ÿÆ€åÿ±Ÿá ÿ®Ÿáÿ™ÿ±€åŸÜ ŸÖÿØŸÑ\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"best_model.pt\")\n",
        "        print(f\"üíæ Saved best model at epoch {epoch+1} with val loss {val_loss:.4f}\")\n",
        "\n",
        "    # üìà ŸÑÿß⁄Ø‚Äå⁄Ø€åÿ±€å ÿØÿ± wandb\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"lr\": scheduler.get_last_lr()[0],\n",
        "        **{f\"AUC_{k}\": v for k, v in auc_scores.items()}\n",
        "    })\n",
        "\n",
        "    scheduler.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BeDuRCr4XgC",
        "outputId": "347ad8a2-781e-4e57-f492-0bfde20352db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìö Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-21-1446514709.py:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "üß™ Validating:   0%|          | 0/4 [00:00<?, ?it/s]/tmp/ipython-input-31-2770580418.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "üß™ Validating:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s]/tmp/ipython-input-31-2770580418.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ AUC Atelectasis: 0.6877\n",
            "‚úÖ AUC Cardiomegaly: 0.7956\n",
            "‚úÖ AUC Consolidation: 0.8729\n",
            "‚úÖ AUC Edema: 0.8680\n",
            "‚úÖ AUC Pleural Effusion: 0.8901\n",
            "üíæ Saved best model at epoch 1 with val loss 0.9185\n",
            "\n",
            "üìö Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-21-1446514709.py:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "üß™ Validating:   0%|          | 0/4 [00:00<?, ?it/s]/tmp/ipython-input-31-2770580418.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "üß™ Validating:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s]/tmp/ipython-input-31-2770580418.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "                                                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ AUC Atelectasis: 0.6156\n",
            "‚úÖ AUC Cardiomegaly: 0.7951\n",
            "‚úÖ AUC Consolidation: 0.8631\n",
            "‚úÖ AUC Edema: 0.8527\n",
            "‚úÖ AUC Pleural Effusion: 0.8936\n",
            "\n",
            "üìö Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r/tmp/ipython-input-21-1446514709.py:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "üß™ Validating:   0%|          | 0/4 [00:00<?, ?it/s]/tmp/ipython-input-31-2770580418.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "üß™ Validating:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.40it/s]/tmp/ipython-input-31-2770580418.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "                                                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ AUC Atelectasis: 0.7073\n",
            "‚úÖ AUC Cardiomegaly: 0.7459\n",
            "‚úÖ AUC Consolidation: 0.8729\n",
            "‚úÖ AUC Edema: 0.8309\n",
            "‚úÖ AUC Pleural Effusion: 0.8824\n",
            "\n",
            "üìö Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r/tmp/ipython-input-21-1446514709.py:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import gc\n",
        "\n",
        "# gc.collect()          # ÿ¨ŸÖÿπ‚Äåÿ¢Ÿàÿ±€å ÿ≠ÿßŸÅÿ∏Ÿá ÿ¢ÿ≤ÿßÿØ ÿ¥ÿØŸá ÿØÿ± Ÿæÿß€åÿ™ŸàŸÜ\n",
        "# torch.cuda.empty_cache()  # ÿ¢ÿ≤ÿßÿØÿ≥ÿßÿ≤€å ⁄©ÿ¥ ÿ≠ÿßŸÅÿ∏Ÿá GPU\n"
      ],
      "metadata": {
        "id": "g3jK15v_Xssl"
      },
      "execution_count": 35,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}